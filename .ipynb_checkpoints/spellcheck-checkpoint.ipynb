{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "import csv\n",
    "import timeit\n",
    "\n",
    "### preprocessing dictionary ###\n",
    "\n",
    "def tokenize(text):\n",
    "    # separate text into words, normalize to lower case\n",
    "    return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "## create dictionary of words from training corpus\n",
    "WORDS = Counter(tokenize(open('big.txt').read()))\n",
    "##  count of number of words in corpus\n",
    "N=sum(WORDS.values())\n",
    "## \n",
    "\n",
    "### end preprocess ###\n",
    "\n",
    "def oneedit(word):\n",
    "    ## all strings 1 edit away from word \n",
    "    # one character edit f(x) from Peter Norvig @ https://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def twoedit(word): \n",
    "    # two edits away from word\n",
    "    w = []\n",
    "    for e1 in oneedit(word):\n",
    "        for e2 in oneedit(e1):\n",
    "            w.append(e2)\n",
    "    return w\n",
    "\n",
    "def threeedit(word): \n",
    "    # three edits away from word\n",
    "    w = []\n",
    "    for e1 in oneedit(word):\n",
    "        for e2 in oneedit(e1):\n",
    "            for e3 in oneedit(e2):\n",
    "                w.append(e3)\n",
    "    return w\n",
    "\n",
    "def realwords(words): \n",
    "    # checks param words with WORDS dict, returns array k with matched words \n",
    "    k = []\n",
    "    for w in words:\n",
    "        if w in WORDS:\n",
    "            k.append(w)\n",
    "    return k\n",
    "\n",
    "def prob(word): \n",
    "    # find prob of word\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correct(word):\n",
    "    # create set, starting with one edit. if not, go to two, if not, go to three\n",
    "    #  |\n",
    "    # \\/ too expensive for larger input texts, good for smaller obscurely spelled texts\n",
    "    #candidates = (known(oneedit(word)) or known(twoedit(word)) or known(threeedit(word)) or [word])\n",
    "\n",
    "    # create set with only 1 or 2 edits, three is too slow\n",
    "    candidates = (realwords(oneedit(word)) or realwords(twoedit(word)) or [word])\n",
    "\n",
    "    \n",
    "    # return sorted list of corrections, based on probability. max 5 words\n",
    "    return sorted(candidates, key=prob, reverse=True)[:3]\n",
    "\n",
    "def commonmis(l, r):\n",
    "    # first pass, find common mispelling from dictionary\n",
    "    # SCRAPPED: speed does not decrease by much\n",
    "    with open(\"spell-errors.txt\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\n')\n",
    "        for row in reader:\n",
    "            i = str(row).split(\":\")\n",
    "            l.append(tokenize(i[0]))\n",
    "            r.append(tokenize(i[1]))\n",
    "                     \n",
    "l = []\n",
    "r = []\n",
    "commonmis(l, r)\n",
    "\n",
    "def spellcheck(text):\n",
    "    print(\"---------------\")\n",
    "    print(\"incorrect words\")\n",
    "    print(\"---------------\")\n",
    "    \n",
    "    IWORDS = Counter(tokenize(open(text).read()))\n",
    "    \n",
    "    for i in IWORDS:\n",
    "        if i in r:\n",
    "            print('in r')\n",
    "        if i not in WORDS:\n",
    "            print(i,':', correct(i))\n",
    "\n",
    "    txt = open('big.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "incorrect words\n",
      "---------------\n",
      "leetcode : ['leetcode']\n",
      "techlead : ['techlead']\n",
      "silicon : ['silicon']\n",
      "The time difference is : 0.4027951190000181\n"
     ]
    }
   ],
   "source": [
    "# spellcheck(\"input.txt\")\n",
    "\n",
    "start = timeit.default_timer()\n",
    "result = spellcheck(\"This is the test of how fast my code is and proof i do leetcode cause i am the TechLead best in Silicon Valley\")\n",
    "stop = timeit.default_timer()\n",
    "print(\"The time difference is :\", stop - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
